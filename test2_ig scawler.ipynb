{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "前言：\n",
    "以行銷領域而言，最常在爬搜使用者的社群留言時使用到爬蟲工具，如Dcard、IG、NEWS…，社群行銷又以IG平台最為熱門，故本次的爬蟲作業，選擇以如何爬搜IG貼文與留言，分為兩個子題：\n",
    "\n",
    "1. 備份自己的貼文圖片\n",
    "2. 爬搜HASHTAG、公開帳號的數值、貼文與留言\n",
    "\n",
    "參考網頁：\n",
    "1.https://www.danielherediamejias.com/scraping-on-instagram-with-instagram-scraper-and-python/\n",
    "2. https://medium.com/marketingdatascience/%E8%B7%9F%E8%91%97ig%E6%BD%AE%E6%B5%81%E4%BE%86%E7%88%AC%E8%9F%B2-%E5%A6%82%E4%BD%95%E7%88%AC%E5%8F%96ig%E8%B2%BC%E6%96%87%E8%AE%9A%E6%95%B8-%E7%95%99%E8%A8%80%E6%95%B8-%E7%B3%BB%E5%88%973-%E9%99%84python%E7%A8%8B%E5%BC%8F%E7%A2%BC-5ab2b7de055d\n",
    "3. https://toyo0103.blogspot.com/2018/01/selenium-webdriver-instagram.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install instagram-scraper\n",
    "# 1. 備份自己文章與圖片\n",
    "\n",
    "# instagram_scraper <jjr_yaya> #Scraping is done anonymously. \n",
    "instagram-scraper jjr_yaya -u jjr_yaya -p *** #You log into your account and you make the scraping from there. Can be useful for private accounts. \n",
    "# instagram-scraper tingyu0421 -u jjr_yaya -p afce556633\n",
    "# instagram-scraper <hashtag> --tag #Important! Don't include # when you enter the hashtag.\n",
    "instagram-scraper psg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from igramscraper.instagram import Instagram \n",
    "\n",
    "proxies = {\n",
    "    '192.168.43.249'\n",
    "}\n",
    "\n",
    "instagram = Instagram()\n",
    "instagram.set_proxies(proxies)\n",
    "\n",
    "account = instagram.get_account('jjr_yaya')\n",
    "\n",
    "# Available fields\n",
    "print('Account info:')\n",
    "print('Id: ', account.identifier)\n",
    "print('Username: ', account.username)\n",
    "print('Full name: ', account.full_name)\n",
    "print('Biography: ', account.biography)\n",
    "print('Profile pic url: ', account.get_profile_picture_url())\n",
    "print('External Url: ', account.external_url)\n",
    "print('Number of published posts: ', account.media_count)\n",
    "print('Number of followers: ', account.followed_by_count)\n",
    "print('Number of follows: ', account.follows_count)\n",
    "print('Is private: ', account.is_private)\n",
    "print('Is verified: ', account.is_verified)\n",
    "\n",
    "# or simply for printing use \n",
    "print(account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Account info.csv', 'w', newline='',encoding=\"utf-8\") as csvfile:\n",
    "  writer = csv.writer(csvfile, delimiter=';')\n",
    "  # writer.writerow([account])\n",
    "  writer.writerow(['identifier','username','full_name',\n",
    "                   'profile_picture_url',\n",
    "                   'external_url','media_count',\n",
    "                   'followed_by_count','follows_count',\n",
    "                   'account.is_private','account.is_verified'])\n",
    "  writer.writerow([account.identifier, account.username, account.full_name, \n",
    "                   account.get_profile_picture_url(),\n",
    "                   account.external_url, account.media_count,\n",
    "                   account.followed_by_count, account.follows_count,\n",
    "                   account.is_private, account.is_verified])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬取IG貼文短連結\n",
    "# https://medium.com/marketingdatascience/%E8%B7%9F%E8%91%97ig%E6%BD%AE%E6%B5%81%E4%BE%86%E7%88%AC%E8%9F%B2-%E5%A6%82%E4%BD%95%E7%88%AC%E5%8F%96ig%E8%B2%BC%E6%96%87%E7%9F%AD%E9%80%A3%E7%B5%90-%E7%B3%BB%E5%88%972-%E9%99%84python%E7%A8%8B%E5%BC%8F%E7%A2%BC-465b7f00eeee\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import time\n",
    "\n",
    "browser = webdriver.Chrome(./chromedriver)  \n",
    "url = 'https://www.instagram.com/jjr_yaya/'\n",
    "browser.get(url) # 前往該網址\n",
    "\n",
    "\n",
    "# 往下滑並取得新的貼文連結\n",
    "n_scroll = 5\n",
    "post_url = []\n",
    "for i in range(n_scroll):\n",
    "    scroll = 'window.scrollTo(0, document.body.scrollHeight);'\n",
    "    browser.execute_script(scroll)\n",
    "    html = browser.page_source\n",
    "    soup = Soup(html, 'lxml')\n",
    "\n",
    "    # 尋找所有的貼文連結\n",
    "    for elem in soup.select('article div div div div a'):\n",
    "        # 如果新獲得的貼文連結不在列表裡，則加入\n",
    "        if elem['href'] not in post_url:\n",
    "            post_url.append(elem['href'])\n",
    "    time.sleep(2) # 等待網頁加載\n",
    "\n",
    "# 總共加載的貼文連結數\n",
    "print(\"總共取得 \" + str(len(post_url)) + \" 篇貼文連結\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 開始爬取貼文讚數及留言數\n",
    "# https://aitmr1234567890.medium.com/%E8%B7%9F%E8%91%97ig%E6%BD%AE%E6%B5%81%E4%BE%86%E7%88%AC%E8%9F%B2-%E5%A6%82%E4%BD%95%E7%88%AC%E5%8F%96ig%E8%B2%BC%E6%96%87%E8%AE%9A%E6%95%B8-%E7%95%99%E8%A8%80%E6%95%B8-%E7%B3%BB%E5%88%973-%E9%99%84python%E7%A8%8B%E5%BC%8F%E7%A2%BC-4ac918b8fef4\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "# 進入到粉專的頁面\n",
    "# browser = webdriver.Chrome()  \n",
    "url = 'https://www.instagram.com/jjr_yaya/'\n",
    "browser.get(url) # 前往該網址\n",
    "\n",
    "# post_url = '/p/CEriQnOMwW9/'\n",
    "post_url = 'p/CJiw6v4MXTkuXmZthbXdXJRadDeG8NKhfg5-9k0/'\n",
    "find = False\n",
    "# 不在目前的網頁元素裡，則往下滑，加載新貼文\n",
    "while not find:\n",
    "    try:\n",
    "        # 找到對應的貼文，鼠標移入\n",
    "        post_elem = browser.find_element_by_xpath('//a[@href=\"'+str(p/CJiw6v4MXTkuXmZthbXdXJRadDeG8NKhfg5-9k0/)+'\"]')\n",
    "        action = ActionChains(browser)\n",
    "        action.move_to_element(post_elem).perform()\n",
    "        # 找到需要的網頁元素\n",
    "        n_like_elem = browser.find_elements_by_class_name('-V_eO')\n",
    "        # 取得讚數、留言數\n",
    "        n_like = n_like_elem[0].text\n",
    "        n_comment = n_like_elem[1].text\n",
    "        # 找到之後就可以回傳‘找到了’\n",
    "        find = True\n",
    "    except:\n",
    "        # 找不到就往下滑\n",
    "        scroll = 'window.scrollBy(0,250)'\n",
    "        browser.execute_script(scroll)\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
